{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import quandl\n",
    "import pandas as pd\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "api_key = open('quandlapikey.txt','r').read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def state_list():\n",
    "    fiddy_states = pd.read_html('https://simple.wikipedia.org/wiki/List_of_U.S._states')\n",
    "    #print(fiddy_states)\n",
    "    return fiddy_states[0][1][1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grab_initial_state_HPI():\n",
    "    states = state_list()\n",
    "    main_df = pd.DataFrame()\n",
    "    \n",
    "    for abbv in states:\n",
    "        print(\"FMAC/HPI_\"+str(abbv))\n",
    "        query = \"FMAC/HPI_\"+str(abbv)\n",
    "        df = quandl.get(query, authtoken=api_key, start_date=\"1999-01-31\")\n",
    "        df.columns = [str(abbv)]\n",
    "    \n",
    "        if main_df.empty:\n",
    "            main_df = df\n",
    "        else:\n",
    "            main_df = main_df.join(df)\n",
    "    \n",
    "    print('\\n')\n",
    "    print(main_df.head())\n",
    "    \n",
    "    pickle_out = open('fiddy_states.pickle','wb')\n",
    "    pickle.dump(main_df, pickle_out)\n",
    "    pickle_out.close()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FMAC/HPI_AL\n",
      "FMAC/HPI_AK\n",
      "FMAC/HPI_AZ\n",
      "FMAC/HPI_AR\n",
      "FMAC/HPI_CA\n",
      "FMAC/HPI_CO\n",
      "FMAC/HPI_CT\n",
      "FMAC/HPI_DE\n",
      "FMAC/HPI_FL\n",
      "FMAC/HPI_GA\n",
      "FMAC/HPI_HI\n",
      "FMAC/HPI_ID\n",
      "FMAC/HPI_IL\n",
      "FMAC/HPI_IN\n",
      "FMAC/HPI_IA\n",
      "FMAC/HPI_KS\n",
      "FMAC/HPI_KY\n",
      "FMAC/HPI_LA\n",
      "FMAC/HPI_ME\n",
      "FMAC/HPI_MD\n",
      "FMAC/HPI_MA\n",
      "FMAC/HPI_MI\n",
      "FMAC/HPI_MN\n",
      "FMAC/HPI_MS\n",
      "FMAC/HPI_MO\n",
      "FMAC/HPI_MT\n",
      "FMAC/HPI_NE\n",
      "FMAC/HPI_NV\n",
      "FMAC/HPI_NH\n",
      "FMAC/HPI_NJ\n",
      "FMAC/HPI_NM\n",
      "FMAC/HPI_NY\n",
      "FMAC/HPI_NC\n",
      "FMAC/HPI_ND\n",
      "FMAC/HPI_OH\n",
      "FMAC/HPI_OK\n",
      "FMAC/HPI_OR\n",
      "FMAC/HPI_PA\n",
      "FMAC/HPI_RI\n",
      "FMAC/HPI_SC\n",
      "FMAC/HPI_SD\n",
      "FMAC/HPI_TN\n",
      "FMAC/HPI_TX\n",
      "FMAC/HPI_UT\n",
      "FMAC/HPI_VT\n",
      "FMAC/HPI_VA\n",
      "FMAC/HPI_WA\n",
      "FMAC/HPI_WV\n",
      "FMAC/HPI_WI\n",
      "FMAC/HPI_WY\n",
      "\n",
      "\n",
      "                   AL         AK         AZ         AR         CA         CO  \\\n",
      "Date                                                                           \n",
      "1999-01-31  93.996295  93.383452  89.510973  94.166885  78.517025  82.010901   \n",
      "1999-02-28  94.295166  93.623900  89.967931  94.151461  79.240130  82.544428   \n",
      "1999-03-31  94.818712  94.254621  90.564311  94.308057  80.224085  83.172332   \n",
      "1999-04-30  95.310083  95.154568  91.075949  94.771727  81.399402  84.073736   \n",
      "1999-05-31  95.741460  95.912283  91.504302  95.438282  82.591329  85.322690   \n",
      "\n",
      "                   CT         DE         FL         GA    ...             SD  \\\n",
      "Date                                                      ...                  \n",
      "1999-01-31  85.014498  87.748899  86.790055  88.547904    ...      91.668852   \n",
      "1999-02-28  85.301017  88.210794  87.252003  89.082613    ...      92.173902   \n",
      "1999-03-31  85.810738  88.785355  87.793717  89.747361    ...      92.889328   \n",
      "1999-04-30  86.848680  89.486157  88.285750  90.463758    ...      93.802116   \n",
      "1999-05-31  88.116750  90.492275  88.886995  91.222170    ...      94.689692   \n",
      "\n",
      "                   TN         TX         UT         VT         VA         WA  \\\n",
      "Date                                                                           \n",
      "1999-01-31  94.514189  88.350929  95.467422  86.833454  87.302684  90.072043   \n",
      "1999-02-28  94.964499  88.815131  95.712081  87.027564  87.688921  90.817135   \n",
      "1999-03-31  95.462608  89.770915  96.232281  87.474765  88.176953  91.758952   \n",
      "1999-04-30  95.773521  90.571896  96.829750  88.254526  88.899561  92.614029   \n",
      "1999-05-31  95.998220  91.307192  97.352296  89.320679  89.710086  93.411621   \n",
      "\n",
      "                   WV         WI         WY  \n",
      "Date                                         \n",
      "1999-01-31  95.667279  89.879436  91.092460  \n",
      "1999-02-28  95.813511  90.292842  91.210016  \n",
      "1999-03-31  96.163282  91.154370  91.761099  \n",
      "1999-04-30  96.666074  92.150414  92.679086  \n",
      "1999-05-31  97.113371  93.060868  93.678555  \n",
      "\n",
      "[5 rows x 50 columns]\n"
     ]
    }
   ],
   "source": [
    "#grab_initial_state_HPI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   AL         AK         AZ         AR         CA         CO  \\\n",
      "Date                                                                           \n",
      "1999-01-31  93.996295  93.383452  89.510973  94.166885  78.517025  82.010901   \n",
      "1999-02-28  94.295166  93.623900  89.967931  94.151461  79.240130  82.544428   \n",
      "1999-03-31  94.818712  94.254621  90.564311  94.308057  80.224085  83.172332   \n",
      "1999-04-30  95.310083  95.154568  91.075949  94.771727  81.399402  84.073736   \n",
      "1999-05-31  95.741460  95.912283  91.504302  95.438282  82.591329  85.322690   \n",
      "\n",
      "                   CT         DE         FL         GA    ...             SD  \\\n",
      "Date                                                      ...                  \n",
      "1999-01-31  85.014498  87.748899  86.790055  88.547904    ...      91.668852   \n",
      "1999-02-28  85.301017  88.210794  87.252003  89.082613    ...      92.173902   \n",
      "1999-03-31  85.810738  88.785355  87.793717  89.747361    ...      92.889328   \n",
      "1999-04-30  86.848680  89.486157  88.285750  90.463758    ...      93.802116   \n",
      "1999-05-31  88.116750  90.492275  88.886995  91.222170    ...      94.689692   \n",
      "\n",
      "                   TN         TX         UT         VT         VA         WA  \\\n",
      "Date                                                                           \n",
      "1999-01-31  94.514189  88.350929  95.467422  86.833454  87.302684  90.072043   \n",
      "1999-02-28  94.964499  88.815131  95.712081  87.027564  87.688921  90.817135   \n",
      "1999-03-31  95.462608  89.770915  96.232281  87.474765  88.176953  91.758952   \n",
      "1999-04-30  95.773521  90.571896  96.829750  88.254526  88.899561  92.614029   \n",
      "1999-05-31  95.998220  91.307192  97.352296  89.320679  89.710086  93.411621   \n",
      "\n",
      "                   WV         WI         WY  \n",
      "Date                                         \n",
      "1999-01-31  95.667279  89.879436  91.092460  \n",
      "1999-02-28  95.813511  90.292842  91.210016  \n",
      "1999-03-31  96.163282  91.154370  91.761099  \n",
      "1999-04-30  96.666074  92.150414  92.679086  \n",
      "1999-05-31  97.113371  93.060868  93.678555  \n",
      "\n",
      "[5 rows x 50 columns]\n"
     ]
    }
   ],
   "source": [
    "pickle_in = open('fiddy_states.pickle','rb')\n",
    "HPI_data = pickle.load(pickle_in)\n",
    "print(HPI_data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# There are also pandas own pickling methodology.\n",
    "# more faster when dealing with astronomical data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "HPI_data.to_pickle('pickle.pickle')\n",
    "HPI_data2 = pd.read_pickle('pickle.pickle')\n",
    "print(HPI_data2.head())\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
